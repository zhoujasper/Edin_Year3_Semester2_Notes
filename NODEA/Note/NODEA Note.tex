\documentclass[9pt]{article}

\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{ctex}
\usepackage{enumitem}
\usepackage{longtable}
\usepackage{makecell} % 换行

% 使用分栏宏包
\usepackage{multicol} 
\usepackage{multirow}
\setlength{\columnseprule}{0.4pt} % 分割线

% 设置字体
\usepackage{unicode-math}
\setmainfont{Cambria}
\setmathfont{Cambria Math}

% 调整页面布局
\usepackage[a4paper, top=0.7cm, bottom=1cm, left=0.7cm, right=.7cm]{geometry}
\setlength{\footskip}{15pt}

% 设置页脚/页眉
\usepackage{fancyhdr}
\fancyfoot[C]{Copyright By Jingren Zhou | Page \thepage}
\fancyhead[]{}
\pagestyle{fancy}
% 去除线
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% 设置 section/subsection 之间的行间距
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{0pt}{0pt}
\titlespacing*{\subsection}{0pt}{0pt}{0pt}

% 调整标题上下间距
\usepackage{titling}
\setlength{\droptitle}{-2.4cm} % 负值表示向上移动

% 设置标题，作者，时间
\title{NODEA Note}
\author{}
\date{}

% 正文
\begin{document}


% 标题
\maketitle
\thispagestyle{fancy}
\vspace{-3.5cm}

% 字体大小
\fontsize{10pt}{11pt}\selectfont
\setlength{\parindent}{8pt}


\section{Basic Knowledge} % Basic Knowledge

\textbf{Def of ODE \& ODEs}: { (1st order)} ODE: $\frac{dy}{dt}=f(t,y)$ \quad \& \quad ODEs: $\frac{d\mathbf{y}}{dt}=\mathbf{f}(t,\mathbf{y})$ , {\footnotesize $\mathbf{y}=(y_1,...,y_d)^T,\mathbf{f}(t,\mathbf{y})=(f_1(t,\mathbf{y}),...,f_d(t,\mathbf{y}))^T$}

\textbf{Autonomous}: $\frac{d\mathbf{y}}{dt}=\mathbf{f}(\mathbf{y})$ \ $\Rightarrow$ \ autonomous ODE(s). \quad \quad \quad || $\Downarrow$ New Autonomous ODEs: $\frac{d\mathbf{y}}{ds}=\mathbf{f}(y_{d+1},\mathbf{y})$ and $\frac{dy_{d+1}}{ds}=1$

$\cdot$ \textbf{Change to Autonomous}: For $\frac{d\mathbf{y}}{dt}=\mathbf{f}(t,\mathbf{y})$. Let $y_{d+1}=t$ and \textit{new} independent variable $s$ s.t. $\frac{dt}{ds}=1$ $\Uparrow$

\textbf{Linearity}: ODE: $\frac{dy}{dt}=f(t,y)$ is linearity if $f(t,y)=a(t)y+b(t)$ \quad || ODEs: {\small If each ODE is linear, then the ODEs are linear.}

\textbf{Picard's Theorem}: If $f(t,y)$ is continuous in $D:=\{(t,y):t_0\leq t\leq T,|y-y_0|<K\}$ and $\exists L>0$ {\footnotesize (Lipschitz constant)} s.t.

$\quad$ $\forall (t,u),(t,v)\in D \quad|f(t,u)-f(t,v)|\leq L|u-v|$ {\tiny (ps:Can use MVT)}. And Assume that $M_f(T-t_0)\leq K,M_f:=\max\{|f(t,u)|:(t,u)\in D\}$

$\quad$ $\Rightarrow$ \textbf{Then}, $\exists$ a unique continuously differentiable solution $y(t)$ to the IVP $\frac{dy}{dt}=f(t,y),y(t_0)=y_0$ on $t\in[t_0,T]$.

\textbf{Existence \& Uniqueness Theorem}: IVP $\frac{d\mathbf{y}}{dt}=\mathbf{f}(t,\mathbf{y}),\mathbf{y}(t_0)=\mathbf{y}_0$. If $f(t,y)$ and $\frac{\partial f}{\partial y_i}$ are continuous in a neighborhood of $(t_0,\mathbf{y}_0)$.

$\quad$ $\Rightarrow$ \textbf{Then}, $\exists I:=(t_0-\delta,t_0+\delta)$ s.t. $\exists$ a unique continuously differentiable solution $\mathbf{y}(t)$ to the IVP on $t\in I$.


\section{Acknowledge} % Acknowledge

\vspace{-10pt}
\begin{longtable}{|c|l||c|l|}
    \hline
    Notation & Meaning & Notation & Meaning \\
    \hline
    \hline
    $[a,b]$ & Approximate function for $t\in[a,b]$ & {\footnotesize $t_0=a \ | \ t_N=b$} & Assume that $t_0=a,t_N=b$ \\
    \hline
    $N$ & number of \textbf{timesteps} \ \ {\tiny (i.e. Break up interval $[a,b]$ into $N$ equal-length sub-intervals)} & $h$ & \textbf{stepsize} \ \ { ($h=\frac{b-a}{N}$)} \\
    \hline
    $t_i$ & Define $N+1$ points: $t_0,t_1,...,t_N$ & $t_m$ & $t_m=a+h\cdot m=t_0+h\cdot m$ \\
    \hline
    $y_i$ & Approximation of $y$ at point $t=t_i$ \ \ (Except $y_0$) & $y(t_i)$ & Exact value of $y$ at point $t=t_i$ \\
    \hline
\end{longtable}
\vspace{-10pt}


\section{Euler's Method and Taylor Series Method} % Euler's Method and Taylor Series Method

\textbf{Euler's Method Algorithm}: Approx $\frac{dy}{dt}=f(t,y),y(t_0)=y_0$ \quad Euler Method: $y_{n+1}=y_n+hf(t_0+nh,y_n)=y_n+hf(t_n,y_n)$

\quad By Taylor Series, for Euler Method, we have: $|le_n|\le|y''(\tau)\cdot\frac{h^2}{2}|$ where $\tau\in[t_n,t_{n+1}]$

\textbf{Lemma}: If $v_{n+1}\leq Av_n+B$ \quad $\Rightarrow$ \quad Then $v_n\leq A^nv_0+\frac{A^n-1}{A-1}B$ \qquad {\scriptsize If $|y''|<M$ and $v_{n}=e_n:=y_n-y(t_n)$, then $A=1+hL,B=h^2M/2$}

\textbf{Boundedness Theorem|Euler Method}: For $\frac{dy}{dt}=f(t,y),y(a)=y_0$:

\qquad $\exists$ \textit{$^1$ unique, $^2$ twice differentiable}, solution $y(t)$ on $[a,b]$, \quad $^3y$ is continuous and \quad $^4|\frac{\partial f}{\partial y}|\leq L$.

\qquad $\Rightarrow$ \ the solution $y_n$ given by \textit{Euler's method} satisfies: $e_n=|y_n-y(t_n)|\leq Dh,D=e^{(b-a)L}\frac{M}{2L}$

\textbf{Order Notation ($\mathcal{O}$)}: we write $z(h)=\mathcal{O}(h^p)$ if $\exists C,h_0>0$ s.t. $|z|\leq Ch^p,0<h<h_0$

\textbf{Flow Map ($\Phi,\Psi$)}: Consider $\frac{dy}{dt}=f(t,y)$.

\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item \textbf{Exact Flow Map ($\Phi$)}: $\Phi_{t_n,h}(y_n)=y(t_n+h)$ \quad {\scriptsize 代表假设 $y(t_n)=y_n$ 的情况下，输入 $y_n$ 在 $t_n+h$ 时刻的精确值; {\tiny 当不写$t_n$角标时,默认要算的前一个时间点已知/精确}}
    \item \textbf{Numerical Flow Map ($\Psi$)}: $\Psi_{t_n,h}(y_n)=y_{n+1}$ \quad {\scriptsize 代表假设 $y(t_n)=y_n$ 的情况下，输入 $y_n$ 在 $t_n+h$ 时刻的数值解; {\tiny 当不写$t_n$角标时,默认要算的前一个时间点已知/精确}} \\
    \textbf{Remark}: $\Phi_h(y(t_n))=y(t_n+h)$ \quad \quad $\Psi_h(y(t_n))=y_{n+1}$ \\
    \textbf{Find}: Generally, use $\Phi_{t_0,h}(y_0)=y(t_0+h)$ to find $y(t_0+h)$; \quad and $\Psi(y)$: Numerical method for ODE.
\end{enumerate}

\textbf{Find Numerical Method|Taylor Series Method}: {\small Approx $\frac{dy}{dt}=f(t,y),y(t_0)=y_0$ with \textit{n-order Methods}}

\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item \textbf{Method}: {\small 通过泰勒展开精确解, 取前$n$项作为近似解, 从而得到数值解.}
    \item \textbf{Taylor Series for $\Phi$}: $\Phi_{t,h}(y)=y+hf(t,y)+\frac{1}{2}h^2[f_t(t,y)+f_y(t,y)f(t,y)]+\frac{1}{6}y'''(t,y)h^3+\cdots$ \quad {\scriptsize (For one variable $y$)} {\tiny ps: $y'=f,y''=f_t+f_yf$}
    \item \textbf{Taylor Series}: $y(t_0+h)=y(t_0)+hy'(t_0)+\frac{h^2}{2}y''(t_0)+\cdots+\frac{h^{n-1}}{(n-1)!}y^{(n-1)}(t_0)+\frac{h^n}{n!}y^{(n)}(t^*),t^*\in[t,t+h]$
\end{enumerate}


\section{Convergence of One-Step Methods {\scriptsize consider for autonomous $y'=f(y)$}} % Convergence of One-Step Methods

\subsection{Convergence | Consistent | Stable} % Convergence | Consistent | Stable
\textbf{Global Error}: global error after $n$ steps: $e_n:=y_n-y(t_n)$ \quad \textbf{Local Error}: {\small For \textit{one-step} method is: $le(y,h)=\Psi_h(y)-\Phi_h(y)$}

ps: More Exactly, $le_n=\Psi_h(y(t_n))-\Phi_h(y(t_n))$.

\textbf{Consistent}: {\small If $||le(y,h)||\leq Ch^{p+1} (\leq \mathcal{O}(h^{p+1})), \ C>0$. $\Rightarrow$ Consistent at order $p$.} \quad \textbf{Stable}: If $||\Psi_h(u)-\Psi_h(v)||\leq(1+h\widehat{L})||u-v||$

\textbf{Convergent}: {\small A method is convergent if:$\forall \ T$, $\lim\limits_{h\to0,\ h=T/N}\max\limits_{n=0,1,...,N}||e_n||=0$} \quad \quad \quad {\small $\Downarrow$ Then the global error satisfies: $\max\limits_{n=0,1,...,N}||e_n||=\mathcal{O}(h^p)$} \ {\tiny \textbf{p-th order}}

\vspace{-2pt}
\textbf{Convergence of One-Step Method}: {\small For $y'=f(y)$, and a one-step method $\Psi_h(y)$ is $^1$ consistent at order $p$ and $^2$ stable with $\widehat{L}\Uparrow$.} \ {\tiny (ps:$C=\frac{C}{\widehat{L}}(e^{T\widehat{L}}-1)$)}


\subsection{More One-Step Methods | Runge-Kutta Methods | Collocation} % More One-Step Methods | Runge-Kutta Methods | Collocation

\textbf{Construction of More General one-step Method}: For $y'=f(y),y(t_0)=y_0$ \ $\Rightarrow$ \ $y(t+h)-y(t)=\int^{t+h}_tf(y(\tau))d\tau$

\textbf{Lagrange Interpolating Polynomials}: For function $p(x)$. Consider points: $(c_1,g_1),...,(c_s,g_s)$. where $p(c_i)=g_i$.

\begin{enumerate}[itemsep=-2pt, topsep=-1pt]
    \item \textbf{Lagrange Interpolating Polynomials}: Let $\ell_{i}(x)=\prod_{j=1,j\ne i}^{s}\frac{x-c_j}{c_i-c_j}\in\mathbb{P}_{s-1}$
    \item \textbf{Polynomial Interpolation}: $\exists!$ $p(x)=\sum_{i=1}^{s}g_i\ell_i(x)$ {\tiny (Can be proved by Honour Algebra)}
\end{enumerate}

\vspace{1pt}
\textbf{Interpolatory Quadrature}: {\footnotesize 对于函数$g(t)\in\mathbb{P}_{p-1}$, 我可以通过插值求积的方法来近似求解积分；以下展示$[a,b]$上的插值求积。}

\begin{enumerate}[itemsep=-2pt, topsep=-1pt]
    \item Choose $c_i$ points in $[a,b]$: $c_1,\dots,c_s$. \quad Let $g_i = g(c_i)$. \quad By using $c_i,g_i$, we can get $\ell_i(x)$.
    \item Define weights: $b_i := \int_a^b \ell_i(x)\,dx$. \quad Then $\int_a^b g(t)\,dt \;\approx\;\sum_{i=1}^{s} b_i\,g(c_i)$.
\end{enumerate}


\textbf{One-Step Collocation Methods}: {\footnotesize 对于$y'=f(y)$, $y_{n+1}=y_n+\int_{t_n}^{t_{n+1}}f(y(t))dt$, 通过Interpolatory Quadrature来近似求解积分.}{\tiny 为了简化,考虑autonomous的情况}

\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item Choose $c_1,...,c_s$ in $[0,1]$, consider $t_i=t_n+c_ih$, then $t_i\in[t_n,t_{n+1}]$.
    \item Let $F_i=f(y(t_i))$, then we can get $\ell_i(x)$ which pass through $(c_i,F_i)$.
    \item Let weights: $b_i=\int_0^1\ell_i(x)dx$, and $a_{ij}=\int_0^{c_i}\ell_j(x)dx$. \quad \textbf{Then} $\star$ $y_{n+1}=y_n+h\sum_{i=1}^{s}b_iF_i$. $\star$
    \item Moreover, we can get: $F_i=f(Y_i)$, where $Y_i=y_n+h\sum_{j=1}^{s}a_{ij}F_j$. \\
    ps: More Exactly, $Y_i=y_n+h\sum^s_{i=1}b_if(t_n+c_ih,Y_i)$ and $y_{n+1}=y_n+h\sum_{i=1}^sb_if(t_n+c_ih,Y_i)$ \\
    \textbf{Remark}: {\footnotesize For choice of $c_i$: The optimal choice is attained by \textit{Gauss-Legendre collocation methods}}. \\
    {\scriptsize e.g. $s=1$: $c_1=\frac{1}{2}$;\qquad $s=2$: $c_1=\frac{1}{2}-\frac{\sqrt{3}}{6},c_2=\frac{1}{2}+\frac{\sqrt{3}}{6}$;\qquad $s=3$: $c_1=\frac{1}{2}-\frac{\sqrt{15}}{10},c_2=\frac{1}{2},c_3=\frac{1}{2}+\frac{\sqrt{15}}{10}$}
\end{enumerate}

\textbf{Runge-Kutta Methods}: Let $y'=f(y)$ here we consider the autonomous case. The RK method has following form:

\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item \textbf{Stage Values}: $Y_i=y_n+h\sum_{j=1}^{s}a_{ij}f(Y_{j})$ \ \ $i\in\{1,...,s\}$ \qquad $F_i=f(Y_i)$
    \item \textbf{Update}: $y_{n+1}=y_n+h\sum_{i=1}^{s}b_iF_i=y_n+h\sum_{i=1}^{s}b_if(Y_i)$ \quad {\small For Autonomous: $c_i=\sum_{j=1}^{s}a_{ij}$} \\
    \textbf{Remark}: Flow-map: $\Psi_{h}(y)=y+h\sum_{i=1}^{s}b_if(Y_i(y))$ \qquad \ {\scriptsize ps:\textit{weights}: $b_i$; \ \textit{internal coefficients}: $a_{ij}$} \\
    \small{ps: We can using \textbf{Butcher Table} to represent the RK method (Appendix) \\
    \textbf{Explicit}: $a_{ij}=0$ for $j\geq i$ { (严格下三角行)} \quad \textbf{Implicit}: $\exists a_{ij}\ne0$ for $j\geq i$ (Not Explicit)}
\end{enumerate}


\subsection{Accuracy of RK Method | Order Condition} % Accuracy of RK Method | Order Condition

\textbf{Some Notations}: If $\mathbf{y}=f'(\mathbf{y})$ where $f(\mathbf{y}):\mathbb{R}^d\to\mathbb{R}^d$. \quad Def $f'=(\frac{\partial f_i}{\partial y_j})$,{\scriptsize $1\leq i\leq d,1\leq j\leq d$} \ {\tiny (行向量)} \qquad $f''=(\frac{\partial^2 f_i}{\partial y_j\partial y_k})$,{\scriptsize $1\leq i\leq d,1\leq j,k\leq d$} 

$\cdot$ Def: {\footnotesize $f''(\mathbf{a},\mathbf{b})=\sum_{j=1}^{d}\sum_{k=1}^{d}\frac{\partial^2 f_i}{\partial y_{j} \ \partial y_{k}}a_jb_k$ \quad $\big|$ $y'=f$ \quad $y''=\sum_{j=1}^{d}\frac{\partial f_i}{\partial y_j}f_j=f'f$ \quad $y'''=\sum_{j=1}^{d}\sum_{k=1}^{d}\frac{\partial^2f_i}{\partial y_j \ \partial y_k}y'_j(t)y'_k(t)+\sum_{j=1}^{d}\frac{\partial f_i}{\partial y_j}y''_j(t)=f''(f,f)+f'f'f$}

$\cdot$ $\Phi_h(y)=y+hf+\frac{h^2}{2}f'f+\frac{h^3}{6}[f''(f,f)+f'f'f]+\mathcal{O}(h^4)$

\textbf{Order Condition}: {\small RK method: $y_{n+1}=y_n+h\sum_{i=1}^{s}b_if(Y_i)$, Let $z(h)=\Phi_h(y)$ 

\hspace{110pt} $\Rightarrow$ If $z'(0)=y',z''(0)=y'',...,z^{(n)}=y^{(n)}$ $\Rightarrow$ { \textbf{Convergent at order $n$}}}

$\cdot$ Order 1: $\sum_{i=1}^{s}b_i=1$ \qquad Order 2: { (add)} $\sum_{i=1}^{s}b_ic_i=\frac{1}{2}$ \qquad Order 3: { (add)} $\sum_{i=1}^{s}b_ic_i^2=\frac{1}{3}$ \ and \ $\sum_{i=1}^{s}\sum_{j=1}^{s}b_ia_{ij}c_j=\frac{1}{6}$


\section{Stability of Runge-Kutta Methods {\scriptsize consider for autonomous $y'=f(y)$}} % Stability of Runge-Kutta Methods

\subsection{Basic Definition for Stability} % Basic Definition for Stability

\textbf{Fixed Point-Exact}: For ODEs $\frac{dy}{dt}=f(y)$, point $y^*$ is fixed point if $f(y^*)=0$ $\Leftrightarrow$ $\Phi_t(y^*)=y^*$ {\footnotesize \ \ \textbf{Set of Fixed Points}: $\mathcal{F}=\{y^*\in\mathbb{R}^d:f(y^*)=0\}$}

\textbf{Fixed Point-Numerical}: \textit{One-step} method $\Psi_h(y)$, point $y^*$ is fixed point if $y^*=\Psi_h(y^*)$ {\footnotesize \ \ \textbf{Set of Fixed Points}: $\mathcal{F}_h=\{y^*\in\mathbb{R}^d:y^*=\Psi_h(y^*)\}$}

\textbf{Theorem}: For Runge-Kutta method, $\mathcal{F}\subseteq\mathcal{F}_h$ \qquad \qquad \textbf{Remark}: {\small $\mathcal{F}_h\subseteq\mathcal{F}$ is NOT always true. \qquad If $\mathcal{F}_h=\mathcal{F}$, then the method is \textbf{regular}.}

$\cdot$ the point in $\mathcal{F}_h\setminus\mathcal{F}$ is called \textbf{spurious fixed point}. \qquad \qquad As $h\to\infty$, the \textit{spurious} fixed points will tends to infinity.

$\cdot$ \textbf{Remark}: For Euler's Method, it's regular. (i.e. $\mathcal{F}_h=\mathcal{F}$)

\textbf{Stability of Fixed Points}: Fixed point $y^*$, the ODEs $\frac{dy}{dt}=f(y)$ with $y(0)=y_0$.
\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item \textbf{Stable in the sense of Lyapunov}: Fixed point $y^*$ is stable if $\forall \varepsilon>0,\exists \delta>0$ s.t. $||y_0-y^*||<\delta\Rightarrow||y(t;y_0)-y^*||<\varepsilon$ $\forall t>0$
    \item \textbf{Asymptotically Stable}: Fixed point $y^*$ is asymptotically stable if $\exists \delta>0$ s.t. $||y_0-y^*||<\delta\Rightarrow\lim\limits_{t\to\infty}||y(t;y_0)-y^*||=0$
    \item \textbf{Unstable}: Fixed point $y^*$ is unstable if it's not stable. \quad i.e. $\exists \epsilon>0,\forall \delta>0$ s.t. $||y_0-y^*||<\delta\Rightarrow||y(t)-y^*||\geq\varepsilon$ for some $t$.
\end{enumerate}


\subsection{Classification of Fixed Points} % Classification of Fixed Points

\textbf{Linearization Theorem}: Suppose $\frac{dy}{dt}=f(y)$, $y^*$ is a fixed point. Let $J=f'(y^*)$ be the Jacobian matrix of $f$ at $y^*$.

\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item If $\forall$ eigenvalues of $J$ in left complex half plane, then $y^*$ is \textbf{asymptotically stable}.
    \item If $\exists$ eigenvalues of $J$ in right complex half plane, then $y^*$ is \textbf{unstable}.
\end{enumerate}

(Following is a special cases from HDE)

\textbf{Generalized Eigenvectors}: If $\lambda$ is an repeated eigenvalue with eigenvalue $\xi$ then:

\quad Generalized Eigenvectors: $\eta$ s.t. $(A-\lambda I)\eta=\xi$ \quad \quad More generally: $(A-\lambda I)\eta_n=\eta_{n-1}$

\textbf{Classification of Critical Points at $y^*$ (Linear)}: \ \ \ \ $r_1,r_2$ be sol of $det(J-\lambda I)=0$. \ \ || \ \ $\mathbb{C}:r=\lambda\pm i\mu(\mu>0)$ 

If $J$ constant, write sol: $\mathbf{x}=c_1e^{r_1t}\xi_1+c_2e^{r_2t}\xi_2$ \ \ || \ \ $GM=1$: $\mathbf{x}=c_1e^{rt}\xi+c_2e^{rt}(t\xi+\eta)$ \qquad {\tiny $J=\begin{pmatrix}\partial_xF(\mathbf{x}_0) & \partial_yF(\mathbf{x}_0) \\ \partial_xG(\mathbf{x}_0) & \partial_yG(\mathbf{x}_0) \\ \end{pmatrix}$} {\tiny If $f(x,y)=\begin{pmatrix}F(x,y) \\ G(x,y)\end{pmatrix}$}

{\tiny
\vspace{-8pt}
\begin{longtable}{|c|l|l|l|l|l|}
    \hline
    {\tiny $\mathbb{R} / \mathbb{C}$} & { Condition || Stability} & Type || Name & Phase Plane Description & Other &  \\
    \hline
    \multirow{7}{*}{$\mathbb{R}$} & { $r_1<r_2<0$ || asy.stab} &  N || NSk & {\tiny 向原点,$\xi_2$直线,$\xi_1$曲线,and $\xi_1$周围$y=\pm x^3$} & { $c_2\ne0,t\to\infty$:$\xi_2$主导方向; \ $c_2=0,t\to\infty$:$\xi_1$主导方向} & \multirow{10}{*}{\tiny \makecell{PS: \\ \textbf{N} = Node \\ \textbf{PN} = Proper Node \\ \textbf{IN} = Improper \\ or: Degenerate Node \\ \textbf{SP} = Saddle Point \\ \textbf{SpP} = spiral point \\ or: Focus Point \\ \textbf{C} = Center \\ \textbf{NSk} = Nodal Sink \\ \textbf{NSo} = Nodal Source}} \\
    \cline{2-5}
    & { $r_1>r_2>0$ || unstable} &  N || NSo & {\tiny 原点向外,$\xi_2$直线,$\xi_1$曲线,and $\xi_1$周围$y=\pm x^3$} & { $c_1\ne0,t\to\infty$:$\xi_1$主导方向; \ $c_1=0,t\to\infty$:$\xi_2$主导方向} & \\
    \cline{2-5}
    & { $r_1>0>r_2$ || unstable} & SP || SP & \makecell{ $t\to\infty$,$\xi_1$从原点向外,$\xi_2$从外向原点 \\  and: 像$y=\pm\frac{1}{x}$,同进同出} & \makecell{ $t\to\pm\infty:|\mathbf{x}|\to\infty$; \ \ \ \ \ $t\to\infty:c_1,c_2\ne0,|\mathbf{x}|\to\infty$,$\xi_1$主导; \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\  $t\to\infty:c_2=0,|\mathbf{x}|\to\infty$,$\xi_1$主导; \ \ \ \ $t\to\infty:c_1=0,|\mathbf{x}|\to0$,$\xi_2$主导} & \\
    \cline{2-5}
    & { $r_1=r_2<0$, {\tiny GM=2} || {\tiny asy.stab}} &  PN || { PN or Stable Star} & { \underline{直线}向原点} & { 直线, $u_1/u_2$ is $t$ independent} & \\
    \cline{2-5}
    & { $r_1=r_2>0$, {\tiny GM=2} || {\tiny unstable}} &  PN || { PN or Unstable Star} & { \underline{直线}从原点向外} & { 直线, $u_1/u_2$ is $t$ independent} & \\
    \cline{2-5}
    & { $r_1=r_2<0$, {\tiny GM=1} || {\tiny asy.stab}} &  IN {\tiny(AL:Type: SpP)} || { IN {\tiny (Stable)}} & { S曲线,向原点} & { $t\to\infty,|\mathbf{x}|\to0,\xi$主导 \ \ \ \ \ \ ps:旋转方向大体和$\eta+c_2\xi$方向相同} & \\
    \cline{2-5}
    & { $r_1=r_2>0$, {\tiny GM=1} || {\tiny unstable}} &  IN {\tiny(AL:Type: SpP)} || { IN {\tiny (Unstable)}} & { S曲线,从原点向外} & { $t\to\infty,|\mathbf{x}|\to\infty,\xi$主导 \ \ \ \ \ \ ps:旋转方向大体和$\eta+c_2\xi$方向相同} & \\
    \cline{1-5}
    \multirow{3}{*}{$\mathbb{C}$} & { $\lambda\ne0,\lambda>0$ || unstable} &  SpP || Unstable Focus & { 向外椭圆(elliptical)螺旋} & { $t\to\infty,|\mathbf{x}|\to\infty$ \ \ \ {\tiny ps:考虑$J=(a,b;c,d)$,如果bc>0,顺时针，如果bc<0,逆时针}} & \\
    \cline{2-5}
    & { $\lambda\ne0,\lambda<0$ || asy.stab} &  SpP || Stable Focus & { 向内椭圆(elliptical)螺旋} & { $t\to\infty,|\mathbf{x}|\to0$ \ \ \ {\tiny ps:考虑$J=(a,b;c,d)$,如果bc>0,顺时针,如果bc<0,逆时针}} & \\
    \cline{2-5}
    & { $\lambda=0$ || stable {\tiny (AL:Indeterminate)}} &  C { (AL:C or SpP)} || C & { 椭圆(elliptical) and 半长轴$\xi$实部方向} & { Bounded trajectory \ \ \ or \ \ \ $\exists$ Periodic Trajectories} & \\
    \hline
\end{longtable}
\vspace{-0.4cm}
}


\subsection{Stability of Fixed Points of Maps (Numerical)}

\textbf{Definition}: For flow map $\Psi$ from $\mathbb{R}^d\to\mathbb{R}^d$. Def $y^{n}(y_0):=$ the $n$-th iterate of $y_0$ under $\Psi$. \ \ {\footnotesize i.e. $y^{n}=y_n$ ; $y_n=\Psi(y_{n-1})$}

\textbf{Stability of Fixed Points of Maps}: Fixed point $y^*$, the map $\Psi$ with $y^*=\Psi(y^*)$.
\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item \textbf{Stable in the sense of Lyapunov}: $y^*$ is stable if $\forall \varepsilon>0,\exists \delta>0$ s.t. $||y_0-y^*||<\delta\Rightarrow||y^{n}(y_0)-y^*||<\varepsilon$ $\forall n\geq0$
    \item \textbf{Asymptotically Stable}: $y^*$ is asymptotically stable if $\exists \delta>0$ s.t. $||y_0-y^*||<\delta\Rightarrow\lim\limits_{n\to\infty}||y^{n}(y_0)-y^*||=0$
    \item \textbf{Unstable}: $y^*$ is unstable if it's not stable. \quad i.e. $\exists \epsilon>0,\forall \delta>0$ s.t. $||y_0-y^*||<\delta\Rightarrow||y^{n}(y_0)-y^*||\geq\varepsilon$ for some $n$.
\end{enumerate}

\textbf{Spectral Radius}: For matrix $K$, $\rho(K)=\max\{|\lambda|:\lambda \ \text{is eigenvalue of} \ K\}$

\textbf{Theorem|Spectral Radius}: Let $z_n=||K^ny_0||$, where $K\in\mathbb{R}^{d\times d}$ is the matrix. Then:

\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item $\rho(K)<1$ $\Leftrightarrow$ $\lim\limits_{n\to\infty}z_n=0$
    \item $\rho(K)>1$ $\Leftrightarrow$ $\lim\limits_{n\to\infty}z_n=\infty$
    \item If $\rho(K)=1$ and \textit{eigenvalues} of $K$ are \textit{semisimple} {\scriptsize (i.e. No generalized eigenvector)}, then $\{z_n\}$ is bounded.
\end{enumerate}

\textbf{Theorem|Connect to Stability}: For smooth $(C^2)$ map $\Psi$, $y^*=\Psi(y^*)$. Let $K=\Psi'(y^*)$, for iteration $y_{n+1}=\Psi(y_n)$, we have: 

\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item $\rho(K)<1$ $\Rightarrow$ $y^*$ is \textit{asymptotically stable}
    \item $\rho(K)>1$ $\Rightarrow$ $y^*$ is \textit{unstable}
\end{enumerate}


\subsection{Linear Stability of Numerical Methods} % Linear Stability of Numerical Methods

\textbf{Special Case|Euler Method}: {\small For $\frac{dy}{dt}=By$, Using Euler method: $y_{n+1}=(I+hB)y_n$. where $\lambda_i$ is eigenvalues of $B$. \quad Assume $f(y)=\lambda y$}
\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item The origin is \textit{stable} if $||I+h\lambda_i||\leq1$ $\forall i$
    \item The origin is \textit{asymptotically stable} if $||I+h\lambda_i||<1$ $\forall i$
    \item The origin is \textit{unstable} if $||I+hB||>1$ \\
    {\footnotesize ps: 即$h\lambda_i$在 复平面上以$z=-1$为圆心,半径为1的圆内$\leftarrow$称为\textbf{Region of absolute stability}}
\end{enumerate}

\textbf{Stability function $R,P$}: Let $P$ be polynomial function and $R$ be rational function.

\quad {\small If RK is \textit{explicit}, then $y_{n+1}=P(\mu)y_n$ \quad ; \quad If RK is \textit{implicit}, then $y_{n+1}=R(\mu)y_n$ \qquad where $\mu=h\lambda$}

\textbf{Stability function $R(\mu)$|Special Case}: For $\frac{dy}{dt}=\lambda y$ \quad {\footnotesize All RK methods can be written as:} \quad {\footnotesize where: $b^T,A$ are from \textit{Butcher Table}. \ \ $\mathbf{1}=[1,...,1]^T$}

\quad \textbf{I}.$Y_i=y_n+\mu\sum^s_{j=1}a_{ij}Y_j$ \quad ($Y=y_n\mathbf{1}+\mu AY$) \qquad $y_{n+1}=y_n+\mu\sum^s_{j=1}b_jY_j=y_n+\mu b^TY$

\quad \textbf{II}.$R(\mu)=1+\mu b^T(I-\mu A)^{-1}\mathbf{1}$ \hspace{80pt} \textbf{III}. $y_{n+1}=R(\mu)y_n$ \qquad where $\mu=h\lambda$

\textbf{Stability function $R(\mu)$|General}: For $\frac{dy}{dt}=By$ \quad {\footnotesize where: $b^T,A$ are from \textit{Butcher Table}. \ \ $\Lambda,U$是B的特征值分解$U^{-1}BU=\Lambda$} \quad {\scriptsize 此时$z_n,y_n$ 是向量}

\quad \textbf{I}. Let $y_n=U z_n$ and $Y_i=UZ_i$:

\qquad Then $Z_{i}=z_n+h\sum_{j=1}^{s}a_{ij}\Lambda Z_j$ \quad {\footnotesize ($Z_j^{(i)}=z_n^{(i)}\mathbf{1}+\mu AZ^{(i)}_j$ \ \ $\forall i$)} \qquad $z_{n+1}=z_n+h\sum_{i=1}^{s}b_i\Lambda Z_i$ \ \ {\footnotesize ($z_{n+1}^{(i)}=z_{n}^{(i)}+\mu\sum^s_{j=1}b_jZ_j^{(i)}$)}

\quad \textbf{II}. $\frac{dz}{dt}=\Lambda z$ \quad $\Rightarrow$ \quad $\frac{dz^{(i)}}{dt}=\lambda_i z^{(i)}$ \quad $\Rightarrow$ \quad $z_{n+1}^{(i)} = R(\mu)z_n^{(i)}$ \quad where $\mu=h\lambda_i$ \qquad {\footnotesize (回到前一个)}

\textbf{Theorem}: For $\frac{dy}{dt}=By$ with $\lambda_1,...,\lambda_d$ be eigenvalues of $B$. The RK method is \textit{stable}|\textit{asy.stab} at \textit{origin} iff:

\quad The Same method also \textit{stable}|\textit{asy.stab} at \textit{origin} for $\frac{dz}{dt}=\lambda_iz$ $\forall i$

\textbf{Corollary}: {\small For $\frac{dy}{dt}=By$ with $B$ diagonalizable. \ \ An RK Method with \textit{stability function} $R(\mu)$ is \textit{stable}|\textit{asy.stab}|\textit{unstable} at \textit{origin} iff: \quad {\tiny Assume $f(y)=\lambda_i y$}}

\quad $|R(\mu)|\leq1$ \ \ or \ \ $|R(\mu)|<1$ \ \ or \ \ $|R(\mu)|>1$ \quad $\forall \mu=h\lambda_i$ $\forall i$ \qquad {\scriptsize we can write $\sigma(B)=\{\lambda_1,...,\lambda_d\}$ the set of eigenvalues of $B$}

\quad \textbf{Remark}: 这里的$R(\mu)$是指$B$分解后的每一个特征值$\lambda_i$的$R(\mu)$,而不是$B$的$R(\mu)$


\subsection{Stability Region and A-stability} % Stability Region and A-stability

\textbf{Stability Region}: {\small $\frac{dy}{dt}=By$. An RK method, the \textit{stability region} is the set of $\mu$ where $\widehat{R}(\mu)=|R(\mu)|<1$.} {\tiny ($f(y)=\lambda y$,如$y$是向量,$R(\mu)$按上面corollary的remark所说)} 

\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item Euler's Method: $\widehat{R}(\mu)=|1+\mu|$ \quad $\Rightarrow$ \quad $\mu\in\{z\in\mathbb{C}:|1+z|<1\}$ {\scriptsize (-1处半径为1的圆)}
    \item Trapezoidal Rule: $\widehat{R}(\mu)=\left|\frac{1+\mu/2}{1-\mu/2}\right|$ \quad $\Rightarrow$ \quad $\mu\in\{z\in\mathbb{C}:|1+z/2|<|1-z/2|\}$ {\scriptsize (left complex half-plane, A-stable)}
    \item Implicit Euler: $\widehat{R}(\mu)=|1-\mu|^{-1}$ \quad $\Rightarrow$ \quad $\mu\in\{z\in\mathbb{C}:|1-z|>1\}$ {\scriptsize (-1处半径为1的圆外侧)}
    \item RK4: $\widehat{R}(\mu)=\left|1+\mu+\frac{\mu^2}{2}+\frac{\mu^3}{6}+\frac{\mu^4}{24}\right|$ \quad $\Rightarrow$ \quad Using $R(\mu)=e^{i\theta}$ to find the region.
\end{enumerate}

\textbf{A-Stable}: An RK method is \textit{A-stable} if its \textit{stability region} contains the entire \textit{left complex half-plane}. {\scriptsize (i.e. $\Re(z)<0$)}


\section{Linear Multistep Methods {\scriptsize consider for autonomous $y'=f(y)$}} % Linear Multistep Methods

\vspace{-6pt}
\quad {\scriptsize Assume $\frac{dy}{dt}=f(y)$ with $y(t_0)=y_0$. \quad Let $y_n'$ denote $f(y_n)$;\qquad Let $y'(t_n)$ denote $f(y(t_n))$}
\vspace{-6pt}

\subsection{Derivation of LMM | Algebra Operators} % Derivation of LMM | Algebra Operators

\textbf{Linear Multistep Methods (LMM)}: {\small For $k$-step LMM:} $\alpha_k y_{n+k}+\sum_{j=0}^{k-1}\alpha_jy_{n+j}=h\sum_{j=0}^{k}\beta_jf(y_{n+j})$ \quad {\footnotesize where $^1\alpha_k\ne0$, $^2$ $\alpha_0\ne0$ or $\beta_0\ne0$}

$\cdot$ ps: Usually, coefficients are \textit{normalized} to have $\alpha_k=1$ or $\sum_{j=0}^{k}\beta_j=1$. \quad \textbf{Implicit}: If $\beta_k\ne0$ \quad \textbf{Explicit}: If $\beta_k=0$

\textbf{AB Schemes Construction|Using Interpolation}: {\footnotesize Adams-Bashforth schemes can be constructed by: Consider $k$ points $(t_{n+j}, y'_{n+j})$ for $j=0,...,k-1$.}

\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item Let $\prod_{k}^{f}(t)$ be the \textit{Lagrange polynomial} which passes through $(t_{n+j}, y'_{n+j})$.
    \item The AB scheme is: $y_{n+k}=y_{n+k-1}+\int_{t_{n+k-1}}^{t_{n+k}}\prod_{k}^{f}(t)dt$ \\
    \textbf{Remark}: Adams-Moulton schemes {\footnotesize 同理: 考虑} $k+1$ points $(t_{n+j}, y'_{n+j})$ for $j=0,...,k$. \\
    Then, we can found $\widehat{\prod}_{k}^{f}(t)$, and \quad $y_{n+k}=y_{n+k-1}+\int_{t_{n+k-1}}^{t_{n+k}}\widehat{\prod}_{k}^{f}(t)dt$
\end{enumerate}

\textbf{Algebra Operators}: Algebra Operators is a function which maps a function to another function.

\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item \textbf{shift operator}: $E_hg(t)=g(t+h)$ \qquad \textbf{forward difference operator}: $\Delta_hg(t)=g(t+h)-g(t)$
    \item \textbf{Identity Operator}: $1g(t)=g(t)$ \qquad \ \ \textbf{Differentiation operator}: $Dg(t)=g'(t)$
    \item \textbf{backward difference operator}: $\nabla_hg(t)=g(t)-g(t-h)$ 
\end{enumerate}

\textbf{Properties of Algebra Operators}:

\begin{longtable}[alignment]{|c|c|c|c|c|c|}
    \hline
    $\Delta_h=E_h-1$ & $E_h=e^{hD}$ & $e^{hD}=1+\Delta_h$ & $D=\frac{1}{h}\ln[1+\Delta_h]$ & $g(t)=e^{(t-t_n)D}g(t_n)$ & $g(t_{n+1})=e^{hD}g(t_n)$ \\
    \hline
    $E_h^{-1} = e^{-hD}$ & \multicolumn{2}{c|}{$D=-\frac{1}{h}\ln[E^{-1}_h]=-\frac{1}{h}\ln[1-\nabla_h]$} & $1-E^{-1}_h=\nabla_h$ & \multicolumn{2}{c|}{$D=\frac{1}{h}[\nabla_h+\frac{1}{2}\nabla^2_h+\frac{1}{3}\nabla^3_h+\cdots]$} \\
    \hline
    \multicolumn{3}{|c|}{\small $e^{hD}g(t)=g(t+h)=g(t)+hDg(t)+\frac{h^2}{2}D^2g(t)+\cdots$} & \multicolumn{3}{c|}{\small $g(t) = \left[1 + \frac{t-t_n}{1!\cdot h}\Delta_h + \frac{(t-t_n)(t-t_n-h)}{2!\cdot h^2}\Delta_h^2 + \frac{(t-t_n)(t-t_n-h)(t-t_n-2h)}{3!\cdot h^3}\Delta_h^3 + \cdots\right]g(t_n)$} \\
    \hline
\end{longtable}
\vspace{-5pt}

\textbf{BDF Method}: For $y'=f(t,y(t))$. \qquad Since $Dy(t)=y'(t)$ and $D=\frac{1}{h}[\nabla_h+\frac{1}{2}\nabla^2_h+\frac{1}{3}\nabla^3_h+\cdots]$.

\qquad\qquad\qquad \ we can get the BDF method by $\frac{1}{h}[\nabla_h+\frac{1}{2}\nabla^2_h+\frac{1}{3}\nabla^3_h+\cdots]y(t)=f(t,y(t))$. {\footnotesize 选择$D$的前几项作为估计.}


\subsection{Order of Accuracy|Consistency} % Order of Accuracy|Consistency

\textbf{First/Second Characteristic Polynomials}: For $k$-step LMM: $\sum_{j=0}^{k}\alpha_jy_{n+j}=h\sum_{j=0}^{k}\beta_jf(y_{n+j})$, we define:

\hspace{190pt}\textbf{First Poly}: $\rho(\zeta)=\sum_{j=0}^{k}\alpha_j\zeta^j$ \qquad\qquad \textbf{Second Poly}: $\sigma(\zeta)=\sum_{j=0}^{k}\beta_j\zeta^j$

\textbf{Linear Case}: For scalar, linear, test equation $y'=\lambda y$, we have $\rho(\zeta)-h\lambda \sigma(\zeta)=0$.

\qquad\qquad\quad \ \ ``General Solution'': $y_n=C_1\zeta_1^n+...+C_k\zeta_k^n$ \quad {\scriptsize where $\zeta_1,...,\zeta_k$ are roots of $\rho(\zeta)-h\lambda \sigma(\zeta)=0$.}

\textbf{Residual}: $r_n:=\sum_{j=0}^{k}\alpha_jy(t_{n+j})-h\sum_{j=0}^{k}\beta_jy'(t_{n+j})$ \qquad {\scriptsize Residual accumulated(累积) in the $n+k-1$-th step.}

\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item \textbf{Taylor Series Expansion|$y(t_{n+j})$}: $y(t_{n+j})=y(t_n)+jhy'(t_n)+\frac{j^2h^2}{2}y''(t_n)+\cdots=\sum_{i=0}^{\infty}\frac{(jh)^i}{i!}y^{(i)}(t_n)$
    \item \textbf{Taylor Series Expansion|$y'(t_{n+j})$}: $y'(t_{n+j})=y'(t_n)+jhy''(t_n)+\frac{j^2h^2}{2}y'''(t_n)+\cdots=\sum_{i=0}^{\infty}\frac{(jh)^i}{i!}y^{(i+1)}(t_n)$
\end{enumerate}

\textbf{Consistency}: An LMM is \textit{consistent} if $r_n=\mathcal{O}(h^{p+1})$ for all sufficiently smooth $f$. \quad with $p$ be the order of the method.

\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item \textbf{Test I}: LMM is \textit{consistent} with order $p$ if: $\sum_{j=0}^{k}\alpha_j=0$ and $\sum_{j=0}^{k}j^i\alpha_j=i\sum_{j=0}^{k}j^{i-1}\beta_j$ for $i=1,...,p$
    \item \textbf{Test II}: LMM is \textit{consistent} with order $p$ if: $\rho(e^{z})-z\sigma(e^{z})=\mathcal{O}(z^{p+1})$.
    \item \textbf{Test III}: LMM is \textit{consistent} with order $p$ if: $\frac{\rho(z)}{\log(z)}-\sigma(z)=\mathcal{O}((z-1)^p)$. \\
    \textbf{Remark}: Test I shows that: $\rho(1)=0$ $\Rightarrow$ 1 is always a root of $\rho(\zeta)=0$. \\
    \textbf{Special Thing}: If it's consistent \ \ $\Rightarrow$ \ \ $\rho'(1)=\sigma(1)$
\end{enumerate}


\subsection{Convergence of LMM} % Convergence of LMM

\textbf{Starting Procedure}: A LLM is incomplete without a starting procedure. \quad {\footnotesize (i.e. 需要初始值 $y_1,...,y_{k-1}$)}

\textbf{Root Condition}: A LMM satisfies the \textit{root condition} if: \ \ $^1$ all roots of $\rho(\zeta)=0$ have modulus $|\zeta|\leq1$. 

\hspace{235pt} $^2$ only one root of $\rho(\zeta)=0$ has modulus $|\zeta|=1$.

\textbf{Convergence Theorem}: {\small A k-step LMM with starting procedure satisfying $\lim_{h\to0}y_j=y(t_0+jh)$ for $j=1,...,k-1$. {\tiny (i.e. 初始值$y_j$收敛到精确值$y(t_0+jh)$)}}

\quad The LMM is convergent \ \ $\Leftrightarrow$ \ \ LMM is consistent with $p\geq1$ and satisfies the root condition.

\quad {\small \textbf{Remark}: If starting procedure is p-th order accurate {\scriptsize (i.e. $y_j=y(t_0+jh)+\mathcal{O}(h^p)$)} \ $\Rightarrow$ \ The LMM is convergent (with order $p$) {\tiny i.e. $\max_{0\leq n\leq N}|y_n-y(t_n)|\leq Ch^p$}}

\textbf{Order of Convergence}: The \textit{maximum} order $p$ of a k-step LLM \textit{satisfying the root condition} is:

\quad $p=k$ (Explicit Method);\quad $p=k+1$ (Implicit Method|odd $k$);\quad $p=k+2$ (Implicit Method|even $k$).


\subsection{Stability}

\textbf{Stability Region}: For a test problem $y'=\lambda y$, let $z=h\lambda$, then k-step LMM have, we consider the equation: $\rho(\zeta)-z\sigma(\zeta)=0$.

\quad The \textit{stability region} is $\mathcal{S}=\{ z\in\mathbb{C}:\rho(\zeta)-z\sigma(\zeta)=0 \ \text{has all roots} \ \zeta \ \text{with} \ |\zeta|<1 \}$

\quad The \textit{boundary of stability region} is $\partial\mathcal{S}=\left\{ z\in\mathbb{C}: z=\frac{\rho(e^{i\theta})}{\sigma(e^{i\theta})} \ , \theta\in[-\pi,\pi] \right\}$

\textbf{A-Stable|Unconditionally Stable}: A LMM is \textit{A-stable} if its \textit{stability region} contains the entire \textit{left complex half-plane}. {\scriptsize (i.e. $\Re(z)<0$)}

\textbf{Theorem}: An A-stable LMM has order $p\leq 2$.

\newpage


\section{Appendix} 

\subsection{Common Numerical Method | Order Condition} % Common Numerical Method | Order Condition

\textbf{One-step Methods}:

\vspace{-10pt}
\begin{table}[ht]
    \centering
    \small
    \begin{tabular}{|l|p{7cm}|c|p{5cm}|}
    \hline
    \textbf{Method} & \textbf{Formula} & \textbf{Order} & \textbf{Stability} \\ \hline
    Euler's Method & 
    \( y_{n+1} = y_n + h\,f(t_n,y_n) \) & 1 & \( \lvert1+h\lambda\rvert < 1 \) \\ \hline
    Backward Euler & 
    \( y_{n+1} = y_n + h\,f(t_{n+1},y_{n+1}) \) & 1 & \( \left\lvert\frac{1}{1-h\lambda}\right\rvert < 1 \) (A-stable) \\ \hline
    Trapezoidal Rule & 
    \( y_{n+1} = y_n + \frac{h}{2}\Big[f(t_n,y_n)+f(t_{n+1},y_{n+1})\Big] \) & 2 & A-stable; \( R(z)=\frac{1+z/2}{1-z/2} \) \\ \hline
    Midpoint Method & 
    \( y_{n+1}=y_n+h\,f\Big(t_n+\frac{h}{2},y_n+\frac{h}{2}f(t_n,y_n)\Big) \) & 2 & \( \left|1+h\lambda+\frac{(h\lambda)^2}{2}\right| < 1 \) \\ \hline
    Heun's Method & 
    \( y_{n+1}=y_n+\frac{h}{2}\Big[f(t_n,y_n)+f\Big(t_{n+1},y_n+h\,f(t_n,y_n)\Big)\Big] \) & 2 & \( \left|1+h\lambda+\frac{(h\lambda)^2}{2}\right| < 1 \) \\ \hline
    Theta Method & 
    \( y_{n+1}=y_n+h\Big[(1-\theta)f(t_n,y_n)+\theta f(t_{n+1},y_{n+1})\Big] \) & 1 (or 2 if \(\theta=\frac{1}{2}\)) & \( R(z)=\frac{1+(1-\theta)z}{1-\theta z} \) \\ \hline
    RK4 Method & 
    见Butcher Table & 4 & \( R(z)=1+z+\frac{z^2}{2}+\frac{z^3}{6}+\frac{z^4}{24} \) \\ \hline
    2-Stage Gauss-Legendre & 
    \begin{minipage}{7cm}
    \[
    \begin{array}{c|cc}
    \frac{1}{2}-\frac{\sqrt{3}}{6} & \frac{1}{4} & \frac{1}{4}-\frac{\sqrt{3}}{6} \\[0.5em]
    \frac{1}{2}+\frac{\sqrt{3}}{6} & \frac{1}{4}+\frac{\sqrt{3}}{6} & \frac{1}{4} \\[0.5em]
    \hline
     & 1/2 & 1/2
    \end{array}
    \]
    \end{minipage} & 4 & A-stable \\ \hline
    \end{tabular}
\end{table}
\vspace{-10pt}

\textbf{Multi-step Methods}:

\begin{longtable}{|l|l|c|l|}
    \hline
    \textbf{Name} & \textbf{Formula} & \textbf{Step} & \textbf{Accuracy} \\
    \hline
    Leapfrog Method & \( y_{n+2} = y_n + 2h\,f(t_{n+1},y_{n+1}) \) & 2 & \\
    \hline
    Adams-Bashforth Method 1 & \( y_{n+1} = y_n + h\,f(t_n,y_n) \) & 1 & \\
    \hline
    Adams-Bashforth Method 2 & \( y_{n+2} = y_{n+1} + \frac{h}{2}\Big[3f(t_{n+1},y_{n+1})-f(t_n,y_n)\Big] \) & 2 & \\
    \hline
    Adams-Bashforth Method 3 & \( y_{n+3} = y_{n+2} + \frac{h}{12}\Big[23f(t_{n+2},y_{n+2})-16f(t_{n+1},y_{n+1})+5f(t_n,y_n)\Big] \) & 3 & \\
    \hline
    Backward Differentiation Formula 2 & \( y_{n+2} = \frac{4}{3}y_{n+1} - \frac{1}{3}y_n + \frac{2h}{3}f(t_{n+2},y_{n+2}) \) & 2 & \\
    \hline
    Backward Differentiation Formula 3 & \( y_{n+3} = \frac{18}{11}y_{n+2} - \frac{9}{11}y_{n+1} + \frac{2}{11}y_n + \frac{6h}{11}f(t_{n+3},y_{n+3}) \) & 3 & \\
    \hline
    \multicolumn{4}{|c|}{\footnotesize Class of Adams-Moulton Methods: $\alpha_k=1,\alpha_{k-1}=-1$, $\alpha_j=0,\forall j<k-1$ \qquad $\big|$ Class of Backward Differentiation Formula (BDF): $\beta_j=0,\forall j<k$} \\
    \hline
\end{longtable}

\textbf{RK Order Condition}
\begin{enumerate}[itemsep=-2pt, topsep=-2pt]
    \item \textbf{order 1}: \( \sum_{i=1}^{s} b_i = 1\)
    \item \textbf{order 2}: \( \sum_{i=1}^{s} b_i c_i = \frac{1}{2}\)
    \item \textbf{order 3}: \( \sum_{i=1}^{s} b_i c_i^2 = \frac{1}{3}\) \quad and \quad \( \sum_{i=1}^{s}\sum_{j=1}^{s} b_i a_{ij} c_j = \frac{1}{6}\)
    \item \textbf{order 4}: \( \sum_{i=1}^{s} b_i c_i^3 = \frac{1}{4}\), \quad \( \sum_{i=1}^{s}\sum_{j=1}^{s} b_i a_{ij} c_j^2 = \frac{1}{8}\), \quad \( \sum_{i=1}^{s}\sum_{j=1}^{s} b_i \,a_{ij} c^2_j = \frac{1}{12}\), \quad \( \sum_{i=1}^{s}\sum_{j=1}^{s}\sum_{k=1}^{s} b_i a_{ij} a_{jk} c_k = \frac{1}{24}\)
\end{enumerate}


\subsection{Useful Series | Common RK Methods} % Useful Series | Common RK Methods

\textbf{Common Runge-Kutta Methods (Butcher Table)}:

\vspace{-5pt}
\begin{minipage}{0.15\linewidth}
    \centering
    \begin{tabular}{c|ccc}
        $c_1$ & $a_{11}$ & $\cdots$ & $a_{1s}$ \\
        $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ \\
        $c_s$ & $a_{s1}$ & $\cdots$ & $a_{ss}$ \\
        \hline
            & $b_1$ & $\cdots$ & $b_s$
    \end{tabular}
    \\~\\
    {Example}
\end{minipage}
\hfill
\begin{minipage}{0.15\linewidth}
    \centering
    \begin{tabular}{c|c}
        0 &  \\
        \hline
          & 1
    \end{tabular}
    \\~\\
    {RK1 \\ (Euler's Method)}
\end{minipage}
\hfill
\begin{minipage}{0.15\linewidth}
    \centering
    \begin{tabular}{c|cc}
        0   &    &  \\
        1   & 1   &  \\
        \hline
            & 1/2 & 1/2
    \end{tabular}
    \\~\\
    {RK2 (Heun's Method)}
\end{minipage}
\hfill
\begin{minipage}{0.2\linewidth}
    \centering
    \begin{tabular}{c|ccc}
        0   &    &    &  \\
        1/2 & 1/2 &    &  \\
        1   & -1  & 2   &  \\
        \hline
            & 1/6 & 2/3 & 1/6
    \end{tabular}
    \\~\\
    {RK3}
\end{minipage}
\hfill
\begin{minipage}{0.3\linewidth}
    \centering
    \begin{tabular}{c|cccc}
        0   &    &    &    &  \\
        1/2 & 1/2 &    &    &  \\
        1/2 & 0   & 1/2 &    &  \\
        1   & 0   & 0   & 1   &  \\
        \hline
            & 1/6 & 1/3 & 1/3 & 1/6
    \end{tabular}
    \\~\\
    {RK4 (Classical/Famous)}
\end{minipage}

\textbf{Useful Series}:

\vspace{-10pt}
\begin{table}[h]
    \centering
    \footnotesize
    \begin{tabular}{|c|c|c|c||c|c|c|c|c|}
        \hline
        \( f(x) \) & Taylor & Series & \( R \) & \( f(x) \) & Taylor & Series & \( R \) \\ 
        \hline
        \( \frac{1}{1-x} \) & \( \sum\limits_{n=0}^{\infty} x^n \) & \( 1 + x + x^2 + x^3 + \dots \) & \( 1 \) &
        \( \frac{1}{(1-x)^2} \) & \( \sum\limits_{n=1}^{\infty} n x^{n-1} \) & \( 1 + 2x + 3x^2 + 4x^3 + \dots \) & \( 1 \) \\ 
        \hline
        \( \frac{2}{(1-x)^3} \) & \( \sum\limits_{n=2}^{\infty} n(n-1)x^{n-2} \) & \( 2 + 6x + 12x^2 + 20x^3 + \dots \) & \( 1 \) &
        \( e^x \) & \( \sum\limits_{n=0}^{\infty} \frac{x^n}{n!} \) & \( 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \dots \) & \( \infty \) \\ 
        \hline
        \( \ln(1+x) \) & \( \sum\limits_{n=1}^{\infty} (-1)^{n+1} \frac{x^n}{n} \) & \( x - \frac{x^2}{2} + \frac{x^3}{3} - \dots \) & \( 1 \) &
        \( -\ln(1-x) \) & \( \sum\limits_{n=1}^{\infty} \frac{x^n}{n} \) & \( x + \frac{x^2}{2} + \frac{x^3}{3} + \dots \) & \( 1 \) \\ 
        \hline
        \( \sin x \) & \( \sum\limits_{n=0}^{\infty} (-1)^n \frac{x^{2n+1}}{(2n+1)!} \) & \( x - \frac{x^3}{3!} + \frac{x^5}{5!} - \dots \) & \( \infty \) &
        \( \cos x \) & \( \sum\limits_{n=0}^{\infty} (-1)^n \frac{x^{2n}}{(2n)!} \) & \( 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \dots \) & \( \infty \) \\ 
        \hline
        \( \arctan x \) & \( \sum\limits_{n=0}^{\infty} (-1)^n \frac{x^{2n+1}}{2n+1} \) & \( x - \frac{x^3}{3} + \frac{x^5}{5} - \dots \) & \( 1 \) &
        \( \sinh x \) & \( \sum\limits_{n=0}^{\infty} \frac{x^{2n+1}}{(2n+1)!} \) & \( x + \frac{x^3}{3!} + \frac{x^5}{5!} + \dots \) & \( \infty \) \\ 
        \hline
        \( \cosh x \) & \( \sum\limits_{n=0}^{\infty} \frac{x^{2n}}{(2n)!} \) & \( 1 + \frac{x^2}{2!} + \frac{x^4}{4!} + \dots \) & \( \infty \) &
        \( (1+x)^k \) & \( \sum\limits_{n=0}^{\infty} \binom{k}{n} x^n \) & \( 1 + kx + \frac{k(k-1)x^2}{2!} + \dots \) & \( 1 \) \\ 
        \hline
        \( \ln x \) & \( \sum\limits_{n=1}^{\infty} (-1)^{n+1} \frac{(x-1)^n}{n} \) & \( (x-1) - \frac{(x-1)^2}{2} + \frac{(x-1)^3}{3} - \dots \) & \( 1, 0<x<2 \) &
        \( \frac{1}{1+x} \) & \( \sum\limits_{n=0}^{\infty} (-1)^n x^n \) & \( 1 - x + x^2 - x^3 + \dots \) & \( 1 \) \\ 
        \hline
    \end{tabular}
\end{table}
\vspace{-10pt}

If $R(z)-e^z=\mathcal{O}(z^{p+1})$, then we can \textit{assume} the order of the method is $p$.

\newpage

\textbf{Inverse of $2\times2$ Matrix}: {\small For $A=\begin{pmatrix} a & b \\ c & d \end{pmatrix}$, we have: $A^{-1}=\frac{1}{ad-bc}\begin{pmatrix} d & -b \\ -c & a \end{pmatrix}$}

\textbf{Explain in one sentence what it means to say that Euler's Method is a first order method}:

On a sufficiently smooth problem, with stepsize $h$ the local error behaves like $\mathcal{O}(h^2)$.

\textbf{Perform a calculation to explain why one typically uses a log-log plot to determine the order $p$ of a numerical method}:

If the global error satisfies $E(h)\approx\mathcal{O}(h^p)$, then taking the logarithm of both sides gives: $\log(E(h))\approx p\log(h)$. So, if we plot $\log(E(h))$ vs. $\log(h)$, the slope of the line will be $p$, indicating the order ($p$) of the method.



\end{document}